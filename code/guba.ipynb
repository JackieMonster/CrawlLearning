{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 1 2 3 4 5 6 7 8 9        日期       最后评论时间   阅读量 评论数    股票代码            股吧名  \\\n",
      "0   11-21  11-21 21:40   415   4  300026          红日药业吧   \n",
      "1   11-21  11-21 21:40   322   4  300377           赢时胜吧   \n",
      "2   11-21  11-21 21:40  2783  16  600336           澳柯玛吧   \n",
      "3   11-21  11-21 21:40   825  10  300021          大禹节水吧   \n",
      "4   11-20  11-21 21:40  1700  23  000001          上证指数吧   \n",
      "..    ...          ...   ...  ..     ...            ...   \n",
      "78  11-20  11-21 21:35   316   5  000001          上证指数吧   \n",
      "79  11-20  11-21 21:35   451  11  000001          上证指数吧   \n",
      "80  11-04  11-21 21:35   748   9  000001          上证指数吧   \n",
      "81  11-21  11-21 21:35    42   0  161131  易方达战略配售(LOF)吧   \n",
      "82  11-20  11-21 21:35   843  21  605066          天正电气吧   \n",
      "\n",
      "                                          内容  \n",
      "0   这里争论很热闹，其实最近这五天，庄家在反复试探杀跌，但都有强力资金抢筹，这间接的  \n",
      "1              准备好资金星期一融券做空、依靠糖球的减持影响力做空吃肉……  \n",
      "2   国人有14亿人口，每人注射两剂疫苗，就是28亿剂，疫苗抗体只能维持6个月左右，一  \n",
      "3                       我说23号有又粗又长的20厘米有人信吗？  \n",
      "4   当前市场，仍然处于震荡折腾，压榨廉价筹码阶段$东岳硅材(SZ300821)$$天  \n",
      "..                                       ...  \n",
      "78  看过只铁大师的著作，他常说的话是：想对，看对，做对。怎么想？想啥？思路在哪里？看  \n",
      "79                                      金枫酒业  \n",
      "80              自己目前的经验教训总结，发出来放在这里是方便提醒自己的。  \n",
      "81  以后再也不会认购什么战略配售基金了。因为旱涝保收，基金公司没有一丝动力去提高基金  \n",
      "82                       蓄势走一波……粗看呈慢高，细瞄有肉肴！  \n",
      "\n",
      "[665 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def tagStringDealing(string):\n",
    "    NewString = string.replace(\"\\n\",'')\n",
    "    NewString = NewString.replace(\"\\r\",'')\n",
    "    NewString = NewString.replace(\" \",\"\")\n",
    "    return NewString\n",
    "              \n",
    "\n",
    "def getHTMLtext(url):\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "\n",
    "        r.raise_for_status()\n",
    "        r.encoding = r.apparent_encoding\n",
    "        soup = BeautifulSoup(r.text,'html.parser')\n",
    "        return soup\n",
    "    except:\n",
    "        return \"ERROR\"\n",
    "\n",
    "def DataDealing(HTML):\n",
    "    Inittag = HTML.find(name = \"ul\",attrs={\"class\":\"newlist\"})\n",
    "    # print(Inittag.find_all(\"li\"))\n",
    "    read=[];quote = [];stockID = []; barName = [];NewsTitle = [];date = [];last = []\n",
    "    for tag in Inittag.find_all(\"li\"):\n",
    "        try:\n",
    "            # print(type(tag))\n",
    "            if isinstance(tag,bs4.element.Tag):\n",
    "        \n",
    "                aTags = tag.span.find_all(\"a\")\n",
    "                href = aTags[0].attrs[\"href\"]\n",
    "                Stkid = re.search(r\"\\d{6}\",href).group(0)\n",
    "                stockID.append(Stkid)\n",
    "                NewsTitle.append(aTags[1].attrs[\"title\"])\n",
    "                barName.append(aTags[0].string)\n",
    "                # print(type(tag))\n",
    "                citeTags = tag.find_all(name = \"cite\")\n",
    "                # print(type(citeTags))\n",
    "                # print(citeTags)\n",
    "                readNum = citeTags[0].string\n",
    "                read.append(int(tagStringDealing(readNum)))\n",
    "                # print(read)\n",
    "                quoteNum = citeTags[1].string\n",
    "                quote.append(int(tagStringDealing(quoteNum)))\n",
    "                date.append(citeTags[3].string)\n",
    "                last.append(citeTags[4].string)\n",
    "                \n",
    "        except:\n",
    "            pass\n",
    "    # print(len(date),len(last),len(read),len(quote),len(stockID),len(barName),len(NewsTitle))\n",
    "    try:\n",
    "        df = pd.DataFrame(np.array([date,last,read,quote,stockID,barName,NewsTitle]).T,columns = [\"日期\",\"最后评论时间\",\"阅读量\",\"评论数\",\"股票代码\",'股吧名',\"内容\"])\n",
    "        return df\n",
    "    except:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def main():\n",
    "    TotalDf = pd.DataFrame()\n",
    "    for i in range(10):#####调整range的范围可以调整爬取的页面数####\n",
    "        url = \"http://guba.eastmoney.com/default,0_\"+str(i)+\".html\" ####获取股吧前十个page的url来爬虫\n",
    "        print(i,end=' ')\n",
    "        soup = getHTMLtext(url)\n",
    "        df = DataDealing(soup)\n",
    "        # print(df)\n",
    "        TotalDf = pd.concat([TotalDf,df],axis = 0)\n",
    "    print(TotalDf)\n",
    "    # TotalDf.to_csv(\"Totaldf.csv\")\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}